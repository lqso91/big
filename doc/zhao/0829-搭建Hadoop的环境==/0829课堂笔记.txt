

Hadoop的起源与背景知识（非常重要：原理的部分）
================================================
一、Google的基本思想：三篇论文
	（一）GFS: Google File System  ---- HDFS: Hadoop Distributed File System
			
			HDFS= NameNode + SecondaryNameNode + DataNode
	
	（二）MapReduce:分布计算模型，问题来源是：PageRank（网页排名）
		1、PageRank（网页排名）
		2、举例：MapReduce的编程模型
		3、演示Demo：单词计数WordCount
		   
		    Yarn = ResourceManager + NodeManager
			
			Example：/root/training/hadoop-2.7.3/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.3.jar
			Yarn的web console：
			http://192.168.157.11:8088
			
			命令：hadoop jar hadoop-mapreduce-examples-2.7.3.jar wordcount /input/data.txt /output/day0829/wc1
	
	（三）BigTable：大表  ------ NoSQL数据库：HBase
		1、关系型数据库：Oracle、MySQL等等  ------> 行式数据库 ------> insert update delete
		2、常见的NoSQL数据库
			（*）Redis：内存数据库
			（*）HBase：面向列  ------> 列式数据库 -----> select
			（*）MongoDB：面向文档（BSON文档：是JSON的二进制）

		3、大表的基本思想：所有的数据存入一张表；通过牺牲空间，换取时间
		   举例：把同样的数据存入Oracle和大表中（HBase中一些基本概念）
	
			HBase = ZooKeeper + HMaster(主节点) + RegionServer（从节点）
	
二、Hadoop的安装与配置
	（一）准备工作
		1、安装Linux和配置Linux
		2、关闭防火墙、配置主机名
		3、安装JDK
		4、解压安装包
			tar -zxvf hadoop-2.7.3.tar.gz -C ~/training/
	
	（二）Hadoop的目录结构
			安装tree命令
			rpm -ivh tree-1.6.0-10.el7.x86_64.rpm
			
			设置Hadoop的环境变量  vi ~/.bash_profile
			HADOOP_HOME=/root/training/hadoop-2.7.3
			export HADOOP_HOME
			
			PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH
			export PATH
			
			生效： source ~/.bash_profile
			
	（三）Hadoop的三种安装模式
		1、本地模式：
			特点：没有HDFS，只能测试MapReduce程序（不是运行在Yarn中，做一个独立的Java程序来运行）
			测试MapReduce程序：
			hadoop jar hadoop-mapreduce-examples-2.7.3.jar wordcount /root/temp/input/data.txt /root/temp/output/wc
			
			注意：路径都是本地Linux的路径
		
		2、伪分布模式
			特点：在单机上，模拟一个分布式的环境，具备Hadoop的所有功能
					HDFS：NameNode + DataNode + SecondaryNameNode
					Yarn：ResourceManager + NodeManager
					
			（*）hadoop-env.sh	JAVA_HOME	/root/training/jdk1.8.0_144
			（*）hdfs-site.xml
					<!--配置数据块的冗余度,默认是3-->
					<!--原则冗余度跟数据节点个数保持一致,最大不要超过3-->
					<property>	
						<name>dfs.replication</name>
						<value>1</value>
					</property>

					<!--是否开启HDFS的权限检查，默认是true-->
					<!--使用默认值，后面会改为false-->
					<!--
					<property>	
						<name>dfs.permissions</name>
						<value>false</value>
					</property>				
                    -->					
			
			（*）core-site.xml
					<!--配置HDFS主节点的地址，就是NameNode的地址-->
					<!--9000是RPC通信的端口-->
					<property>	
						<name>fs.defaultFS</name>
						<value>hdfs://bigdata111:9000</value>
					</property>	

					<!--HDFS数据块和元信息保存在操作系统的目录位置-->
					<!--默认是Linux的tmp目录,一定要修改-->
					<property>	
						<name>hadoop.tmp.dir</name>
						<value>/root/training/hadoop-2.7.3/tmp</value>
					</property>

			（*）mapred-site.xml（默认没有这个文件）
					<!--MR程序运行容器或者框架-->
					<property>	
						<name>mapreduce.framework.name</name>
						<value>yarn</value>
					</property>		

			（*）yarn-site.xml
			        <!--配置Yarn主节点的位置-->
					<property>	
						<name>yarn.resourcemanager.hostname</name>
						<value>bigdata111</value>
					</property>			

					<!--NodeManager执行MR任务的方式是Shuffle洗牌-->
					<property>	
						<name>yarn.nodemanager.aux-services</name>
						<value>mapreduce_shuffle</value>
					</property>	
					
			（*）对HDFS的NameNode进行格式化  -----> 目录：/root/training/hadoop-2.7.3/tmp
					举例：软盘，需要格式化
					
					命令：hdfs namenode -format
					日志：Storage directory /root/training/hadoop-2.7.3/tmp/dfs/name has been successfully formatted.
					
			（*）启动：
					HDFS：start-dfs.sh
					Yarn: start-yarn.sh
					统一的：start-all.sh 
					
					Web Console访问：hdfs: 端口: 50070
					                 yarn: 端口：8088
									 
			（*）免密码登录的原理和配置
					
		3、全分布模式
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
			
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	