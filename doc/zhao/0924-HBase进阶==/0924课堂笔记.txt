
0924课堂笔记
============================================
问题1：linux连不上网得解决办法
问题2：HBase的索引（rowkey也有索引---通常是一个组合行键、二级索引）

一、使用Java API操作HBase

二、搭建HBase的全分布环境和HA
	1、搭建HBase的全分布:
		bigdata112  bigdata113  bigdata114
		
		注意：时间同步
			  如果不同步：（1）Hadoop：执行MR出错
			              （2）HBase：RegionServer会自动停止
	
		bigdata112:  HMaster、ZooKeeper
		bigdata113： RegionServer
		bigdata114： RegionServer
		
		在主节点上 
			解压  tar -zxvf hbase-1.3.1-bin.tar.gz -C ~/training/
			设置环境变量
		hbase-site.xml
		    <!--HBase对应的HDFS目录-->
			<property>
			     <name>hbase.rootdir</name>
				 <value>hdfs://192.168.157.112:9000/hbase</value>
			</property>		

			<!--是一个分布式环境-->
			<property>
			     <name>hbase.cluster.distributed</name>
				 <value>true</value>
			</property>	

			<!--指定ZK的地址-->
			<property>
			     <name>hbase.zookeeper.quorum</name>
				 <value>192.168.157.112</value>
			</property>		

			<property>
			     <name>dfs.replication</name>
				 <value>2</value>
			</property>
			
			<!--允许集群各个节点的时间误差的最大值，单位是毫秒-->
			<property>
			     <name>hbase.master.maxclockskew</name>
				 <value>180000</value>
			</property>

		regionservers
			bigdata113
			bigdata114
			
		把安装目录复制到从节点上
		 scp -r hbase-1.3.1/ root@bigdata113:/root/training
		 scp -r hbase-1.3.1/ root@bigdata114:/root/training
			
	2、搭建HA（不需要单独搭建）
	3、对比：在不同的模式下，HBase在Zk中保存的数据
	
三、数据保存的过程（一定注意：Region的分裂）
	注意：数据的存储，都需要注意。
		HDFS：数据的平衡 -----> 数据的移动（拷贝）
		HBase：数据越来越多 ---> Region的分裂 ---> 数据的移动（拷贝）

四、HBase的过滤器（相当于SQL中的：where语句）
	准备测试数据

五、HBase上的MapReduce：重写WorkCount单词计数
	1、建立输入的表
	   create 'word','content'
	   put 'word','1','content:info','I love Beijing'
	   put 'word','2','content:info','I love China'
	   put 'word','3','content:info','Beijing is the capital of China'
	   
	2、输出表
	   create 'stat','content'
	   
	注意：export HADOOP_CLASSPATH=$HBASE_HOME/lib/*:$CLASSPATH
	   
















